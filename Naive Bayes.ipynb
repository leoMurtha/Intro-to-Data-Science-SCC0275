{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Naive Bayes is a classical ML algorithm used for text analytics and general classification.\n",
    "The following implementation describes the Gaussian Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Algorithm\n",
    "The algorithm it is very statistical based using prior and posterior probabilities of the classes in the dataset.\n",
    "\n",
    "Using the Bayes' Theorem below as the main idea:\n",
    "\n",
    "$$P(A | B)P(B) = P(A \\cap B) = P(B \\cap A) = P(B | A)P(A)$$\n",
    "\n",
    "$$P(A | B) = \\frac{P(B | A)P(A)}{P(B)}$$\n",
    "\n",
    "\n",
    "Now using the theorem we can ask what is the probability of a given class given that a specific document happened.\n",
    "\n",
    "$$P(Class | Document\\{w1,w2,w3,...,wn\\})) = \\frac{P(Document | Class)P(Class)}{P(Document)}$$\n",
    "\n",
    "The equation above describes the full Bayes algorithm but some probabilites are very non pratical to calculate an example of this is the $P(Document)$ because if we have a never seen document in the dataset this $P(Document)$ is going to be $0$.\n",
    "\n",
    "**The term Naive comes from assuming that the variables are independent of each other when they may not be**\n",
    "\n",
    "Then using the independance factor the Bayes' Theorem can be calculated as below:\n",
    "<div>\n",
    "<img src=\"images/BayesSimple.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "In this notebook I'm going to approach the 20 News Group dataset, the steps to solve/classify this dataset are pre-processing the text data, training the Gaussian Bayes Classifier and testing it with unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "* converting all letters to lower or upper case\n",
    "* converting numbers into words or removing numbers\n",
    "* removing punctuations, accent marks and other diacritics\n",
    "* removing white spaces\n",
    "* expanding abbreviations\n",
    "* removing stop words, sparse terms, and particular words\n",
    "* text canonicalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data using sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "\n",
    "#train.data: holds the text data\n",
    "#train.target: holds the id's for the classes\n",
    "#train.target_names: holds the class string names\n",
    "#train.filenames: holds the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class sample [rec.autos]\n",
      "Class sample [comp.sys.mac.hardware]\n",
      "Class sample [comp.sys.mac.hardware]\n",
      "Class sample [comp.graphics]\n",
      "Class sample [sci.space]\n",
      "Class sample [talk.politics.guns]\n",
      "Class sample [sci.med]\n",
      "Class sample [comp.sys.ibm.pc.hardware]\n",
      "Class sample [comp.os.ms-windows.misc]\n",
      "Class sample [comp.sys.mac.hardware]\n",
      "\n",
      "# of docs in the train set 11314\n",
      "# of docs in the test set 7532\n",
      "\n",
      "Example of data(unprocessed) of the class [alt.atheism]:\n",
      "\n",
      "[From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for t in train.target[:10]:\n",
    "\n",
    "    print('Class sample [%s]' % train.target_names[t])\n",
    "\n",
    "print('\\n# of docs in the train set %d\\n# of docs in the test set %d\\n' %\n",
    "      (len(train.target), len(test.target)))\n",
    "print('Example of data(unprocessed) of the class [%s]:\\n\\n[%s]' %\n",
    "      (train.target_names[0], train.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting all letters to lower or upper case\n",
    "converting numbers into words or removing numbers\n",
    "removing emails\n",
    "removing punctuations, accent marks and other diacritics\n",
    "removing white spaces\n",
    "expanding abbreviations\n",
    "removing stop words, sparse terms, and particular words\n",
    "text canonicalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "punctuation = \"\"\"\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?[\\]\\^\\_\\`\\{\\|\\}~\"\"\"\n",
    "\n",
    "# Defining cleaning regexes\n",
    "\n",
    "number_re = re.compile(r'(\\d+)', re.I | re.M | re.U)\n",
    "punkt_re = re.compile(r'([%s])' % punctuation, re.I | re.M | re.U)\n",
    "email_re = re.compile(r'(\\w+\\@\\w+)', re.I | re.M | re.U)\n",
    "\n",
    "whitespaces_re = re.compile(r'(\\s)', re.I | re.M | re.U)\n",
    "\n",
    "\n",
    "def preprocess(doc):\n",
    "    if type(doc) != str:\n",
    "        raise Exception('Doc is not text data')\n",
    "\n",
    "    # Making a copy of the original document\n",
    "    _doc = doc\n",
    "\n",
    "    # Stripping\n",
    "    _doc = _doc.strip()\n",
    "\n",
    "    # lower case\n",
    "    _doc = _doc.lower()\n",
    "\n",
    "    # removing numbers\n",
    "    _doc = number_re.sub('', _doc)\n",
    "\n",
    "    # removing punkt before email so the email regex is simpler\n",
    "    _doc = punkt_re.sub('', _doc)\n",
    "\n",
    "    # removing emails\n",
    "    _doc = email_re.sub('', _doc)\n",
    "\n",
    "    # removing long white spaces to single spacew\n",
    "    _doc = whitespaces_re.sub(' ', _doc)\n",
    "\n",
    "    return (doc, _doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from  subject john  paraphrased lines   at the end of a recent mon  apr  post alastair thomson offers the following paraphrase of john      god loved the world so much that he gave us his son    to die in our place so that we may have eternal life  the to die in our place bothers me since it inserts into the verse a doctrine not found in the original moreover i suspect that the poster intends to affirm not merely substitution but forensic or penal substitution  i maintain that the scriptures in speaking of the atonement teach a doctrine of substitution but not one of forensic substitution  those interested in pursuing the matter are invited to send for my essays on genesis either  thru  on this question or  through  with leadin  the nth essay can be obtained by sending to  or to  the message    get genn ruff   yours  james kiefer   any theologian worth his salt can put anything he wants to say in the form of a commentary on the book of genesis  walter kaufman\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(train.data[123])[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
